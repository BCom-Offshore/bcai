{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a55e33",
   "metadata": {},
   "source": [
    "# BCom Offshore Recommendation Model Development\n",
    "\n",
    "## Train and Export Recommendation Model for Link Performance Optimization\n",
    "\n",
    "This notebook develops a recommendation model trained on site grades to generate actionable insights\n",
    "for improving link performance across the BCom Offshore network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc99007",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, \n",
    "    precision_recall_curve, f1_score, accuracy_score\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Custom modules\n",
    "from app.services.data_loader import get_data_loader\n",
    "from app.services.model_management import ModelManager\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf144643",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataLoader\n",
    "data_loader = get_data_loader('data')\n",
    "\n",
    "# Get customer data for ML\n",
    "customer_id = 4  # Orange MALI\n",
    "print(f\"Loading data for Customer ID: {customer_id}...\")\n",
    "\n",
    "# Get customer summary\n",
    "customer_summary = data_loader.get_customer_summary(customer_id)\n",
    "print(f\"\\nCustomer Summary:\")\n",
    "print(f\"  Networks: {customer_summary.get('network_count', 'N/A')}\")\n",
    "print(f\"  Sites: {customer_summary.get('site_count', 'N/A')}\")\n",
    "print(f\"  Links: {customer_summary.get('link_count', 'N/A')}\")\n",
    "print(f\"  Devices: {customer_summary.get('device_count', 'N/A')}\")\n",
    "\n",
    "# Export ML data\n",
    "ml_data = data_loader.export_customer_data_for_ml(customer_id)\n",
    "print(f\"\\nLoaded {len(ml_data)} records for training\")\n",
    "print(f\"\\nData shape: {ml_data.shape}\")\n",
    "print(f\"Columns: {ml_data.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(ml_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4325a485",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create working copy\n",
    "df = ml_data.copy()\n",
    "\n",
    "# Handle missing values\n",
    "print(f\"Missing values before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing numeric columns with median\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Drop rows with missing target variable\n",
    "df = df.dropna(subset=['grade'])\n",
    "\n",
    "print(f\"\\nMissing values after handling: {df.isnull().sum().sum()}\")\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "# Display statistics\n",
    "print(f\"\\nGrade distribution:\")\n",
    "print(df['grade'].describe())\n",
    "print(f\"\\nGrade value counts:\")\n",
    "print(df['grade'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68197e99",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering for Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable: links needing recommendations (grade < 7 or degrading)\n",
    "df['needs_recommendation'] = (df['grade'] < 7.0).astype(int)\n",
    "\n",
    "print(f\"Recommendation target distribution:\")\n",
    "print(df['needs_recommendation'].value_counts())\n",
    "print(f\"\\nClass balance: {df['needs_recommendation'].value_counts(normalize=True).round(3)}\")\n",
    "\n",
    "# Feature engineering\n",
    "feature_engineering_cols = []\n",
    "\n",
    "# 1. Grade quality score (0-1 scale)\n",
    "df['grade_quality'] = df['grade'] / 10.0\n",
    "feature_engineering_cols.append('grade_quality')\n",
    "\n",
    "# 2. Performance indicators\n",
    "performance_cols = ['availability', 'performance', 'congestion', 'latency']\n",
    "available_perf_cols = [col for col in performance_cols if col in df.columns]\n",
    "feature_engineering_cols.extend(available_perf_cols)\n",
    "\n",
    "# 3. Stability indicators\n",
    "stability_cols = ['ib_instability', 'ob_instability']\n",
    "available_stab_cols = [col for col in stability_cols if col in df.columns]\n",
    "feature_engineering_cols.extend(available_stab_cols)\n",
    "\n",
    "# 4. Degradation factors\n",
    "degradation_cols = ['ib_degradation', 'ob_degradation']\n",
    "available_degrad_cols = [col for col in degradation_cols if col in df.columns]\n",
    "feature_engineering_cols.extend(available_degrad_cols)\n",
    "\n",
    "# 5. Uptime score\n",
    "if 'up_time' in df.columns:\n",
    "    df['uptime_score'] = df['up_time'] / 100.0\n",
    "    feature_engineering_cols.append('uptime_score')\n",
    "\n",
    "# Remove duplicates and clean\n",
    "feature_engineering_cols = list(set(feature_engineering_cols))\n",
    "feature_engineering_cols = [col for col in feature_engineering_cols if col in df.columns]\n",
    "\n",
    "print(f\"\\nFeatures selected for model ({len(feature_engineering_cols)}):\")\n",
    "print(feature_engineering_cols)\n",
    "\n",
    "# Verify all features are numeric\n",
    "for col in feature_engineering_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print(f\"\\nFeature statistics:\")\n",
    "display(df[feature_engineering_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745a023",
   "metadata": {},
   "source": [
    "## 5. Train Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af57c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df[feature_engineering_cols].copy()\n",
    "y = df['needs_recommendation'].copy()\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "mask = X.isnull().any(axis=1) | y.isnull()\n",
    "X = X[~mask]\n",
    "y = y[~mask]\n",
    "\n",
    "print(f\"Training set size: {len(X)}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(f\"\\nFeatures scaled successfully\")\n",
    "print(f\"Scaled features mean: {X_scaled.mean().mean():.6f}\")\n",
    "print(f\"Scaled features std: {X_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69581df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Gradient Boosting model\n",
    "print(\"Training Gradient Boosting Classifier...\")\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Training metrics\n",
    "train_pred = gb_model.predict(X_train)\n",
    "train_pred_proba = gb_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "print(f\"\\nâœ“ Model trained successfully\")\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, train_pred):.4f}\")\n",
    "print(f\"Training AUC-ROC: {roc_auc_score(y_train, train_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bc84b",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fe117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "y_pred = gb_model.predict(X_test)\n",
    "y_pred_proba = gb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"â•\" * 50)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"â•\" * 50)\n",
    "print(f\"Test Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Test AUC-ROC:   {test_auc:.4f}\")\n",
    "print(f\"Test F1-Score:  {test_f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Recommendation', 'Recommend Action']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False)\n",
    "axes[0].set_title('Confusion Matrix', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "axes[0].set_xticklabels(['No Recommend', 'Recommend'])\n",
    "axes[0].set_yticklabels(['No Recommend', 'Recommend'])\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "axes[1].plot(recall, precision, marker='o', linewidth=2, label='Model')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Evaluation plots created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35253f3",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': gb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (Top 10):\")\n",
    "print(feature_importance.head(10).to_string())\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "top_features = feature_importance.head(10)\n",
    "ax.barh(range(len(top_features)), top_features['importance'])\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('Importance Score')\n",
    "ax.set_title('Top 10 Most Important Features for Recommendations', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Feature importance visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770b954",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318238ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_scores = cross_val_score(gb_model, X_scaled, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"\\n5-Fold Cross-Validation Results:\")\n",
    "print(f\"Scores: {cv_scores.round(4)}\")\n",
    "print(f\"Mean: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std Dev: {cv_scores.std():.4f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(range(1, 6), cv_scores, marker='o', linewidth=2, markersize=8)\n",
    "ax.axhline(y=cv_scores.mean(), color='r', linestyle='--', label=f'Mean: {cv_scores.mean():.4f}')\n",
    "ax.fill_between(\n",
    "    range(1, 6),\n",
    "    cv_scores.mean() - cv_scores.std(),\n",
    "    cv_scores.mean() + cv_scores.std(),\n",
    "    alpha=0.2\n",
    ")\n",
    "ax.set_xlabel('Fold')\n",
    "ax.set_ylabel('AUC-ROC Score')\n",
    "ax.set_title('Cross-Validation Results', fontweight='bold')\n",
    "ax.set_xticks(range(1, 6))\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3bdb8",
   "metadata": {},
   "source": [
    "## 9. Save and Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e21dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model manager\n",
    "model_manager = ModelManager()\n",
    "\n",
    "# Prepare model metadata\n",
    "metadata = {\n",
    "    'model_type': 'GradientBoostingClassifier',\n",
    "    'task': 'recommendation_engine',\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'features': X.columns.tolist(),\n",
    "    'feature_count': len(X.columns),\n",
    "    'scaler_type': 'StandardScaler',\n",
    "    'metrics': {\n",
    "        'test_accuracy': float(test_accuracy),\n",
    "        'test_auc_roc': float(test_auc),\n",
    "        'test_f1_score': float(test_f1)\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8\n",
    "    },\n",
    "    'training_timestamp': datetime.now().isoformat(),\n",
    "    'data_source': 'BCom Offshore - Orange MALI Customer',\n",
    "    'description': 'Recommendation engine for identifying links needing performance optimization'\n",
    "}\n",
    "\n",
    "# Save model and scaler\n",
    "print(\"Saving model and preprocessing artifacts...\")\n",
    "model_manager.save_model(\n",
    "    model=gb_model,\n",
    "    model_name='recommendation_engine',\n",
    "    version='1.0.0',\n",
    "    metadata=metadata\n",
    ")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = model_manager.model_dir / 'recommendation_engine' / '1.0.0' / 'scaler.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(f\"âœ“ Model saved to: {model_manager.model_dir}\")\n",
    "print(f\"âœ“ Version: 1.0.0\")\n",
    "print(f\"âœ“ Test AUC-ROC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40cd600",
   "metadata": {},
   "source": [
    "## 10. Model Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ea8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model for inference\n",
    "from app.services.model_loaders import RecommendationModelLoader\n",
    "\n",
    "print(\"Testing inference with saved model...\")\n",
    "\n",
    "# Get a few test samples\n",
    "test_sample_indices = np.where(y_test.values == 1)[0][:3]\n",
    "test_samples = X_test.iloc[test_sample_indices]\n",
    "\n",
    "# Make predictions\n",
    "predictions = gb_model.predict(test_samples)\n",
    "probabilities = gb_model.predict_proba(test_samples)\n",
    "\n",
    "print(\"\\nSample Recommendations:\")\n",
    "print(\"=\"*60)\n",
    "for i, (idx, row) in enumerate(test_samples.iterrows()):\n",
    "    prob_no_rec = probabilities[i][0]\n",
    "    prob_rec = probabilities[i][1]\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Prediction: {'RECOMMEND' if predictions[i] == 1 else 'NO ACTION'}\")\n",
    "    print(f\"  Confidence: {max(prob_no_rec, prob_rec):.2%}\")\n",
    "    print(f\"  Prob(No Recommendation): {prob_no_rec:.4f}\")\n",
    "    print(f\"  Prob(Recommendation): {prob_rec:.4f}\")\n",
    "\n",
    "print(\"\\nâœ“ Inference test completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec603df",
   "metadata": {},
   "source": [
    "## 11. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary report\n",
    "summary_report = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘         RECOMMENDATION MODEL TRAINING SUMMARY                  â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ðŸ“Š DATASET INFORMATION:\n",
    "   â€¢ Total Samples: {len(X)}\n",
    "   â€¢ Training Samples: {len(X_train)}\n",
    "   â€¢ Test Samples: {len(X_test)}\n",
    "   â€¢ Features: {len(X.columns)}\n",
    "   â€¢ Class Balance: {y.value_counts().to_dict()}\n",
    "\n",
    "ðŸ¤– MODEL CONFIGURATION:\n",
    "   â€¢ Algorithm: Gradient Boosting Classifier\n",
    "   â€¢ Estimators: 100\n",
    "   â€¢ Learning Rate: 0.1\n",
    "   â€¢ Max Depth: 5\n",
    "   â€¢ Scaler: StandardScaler\n",
    "\n",
    "ðŸ“ˆ TRAINING PERFORMANCE:\n",
    "   â€¢ Training Accuracy: {accuracy_score(y_train, train_pred):.4f}\n",
    "   â€¢ Training AUC-ROC: {roc_auc_score(y_train, train_pred_proba):.4f}\n",
    "\n",
    "âœ… TEST PERFORMANCE:\n",
    "   â€¢ Test Accuracy: {test_accuracy:.4f}\n",
    "   â€¢ Test AUC-ROC: {test_auc:.4f}\n",
    "   â€¢ Test F1-Score: {test_f1:.4f}\n",
    "   â€¢ CV Mean (5-fold): {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\n",
    "\n",
    "ðŸŽ¯ TOP 3 MOST IMPORTANT FEATURES:\n",
    "   1. {feature_importance.iloc[0]['feature']}: {feature_importance.iloc[0]['importance']:.4f}\n",
    "   2. {feature_importance.iloc[1]['feature']}: {feature_importance.iloc[1]['importance']:.4f}\n",
    "   3. {feature_importance.iloc[2]['feature']}: {feature_importance.iloc[2]['importance']:.4f}\n",
    "\n",
    "ðŸ’¾ MODEL EXPORT:\n",
    "   â€¢ Name: recommendation_engine\n",
    "   â€¢ Version: 1.0.0\n",
    "   â€¢ Location: ml_models/recommendations/1.0.0/\n",
    "   â€¢ Files: model.pkl, scaler.pkl, metadata.json\n",
    "\n",
    "ðŸš€ READY FOR PRODUCTION\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd4e10",
   "metadata": {},
   "source": [
    "## 12. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_steps = \"\"\"\n",
    "ðŸ“‹ NEXT STEPS:\n",
    "\n",
    "1. INTEGRATE WITH API ENDPOINTS:\n",
    "   âœ“ Anomaly detection endpoint: POST /api/v1/anomalies/bcom/device/{device_id}/detect\n",
    "   âœ“ Link recommendations: POST /api/v1/recommendations/bcom/link/{link_id}/recommend\n",
    "   âœ“ Network health report: POST /api/v1/recommendations/bcom/network/{network_id}/health-report\n",
    "   âœ“ Customer improvement plan: GET /api/v1/recommendations/bcom/customer/{customer_id}/improvement-plan\n",
    "\n",
    "2. DATABASE INTEGRATION:\n",
    "   â€¢ Run migrations to create tables\n",
    "   â€¢ Load data with ingestion pipeline\n",
    "   â€¢ Test model inference with live data\n",
    "\n",
    "3. MONITORING & OPTIMIZATION:\n",
    "   â€¢ Track model performance in production\n",
    "   â€¢ Monitor recommendation accuracy\n",
    "   â€¢ Plan for periodic model retraining\n",
    "\n",
    "4. ADVANCED FEATURES:\n",
    "   â€¢ A/B testing for different models\n",
    "   â€¢ Real-time model updates\n",
    "   â€¢ Custom recommendation rules\n",
    "\"\"\"\n",
    "\n",
    "print(next_steps)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
